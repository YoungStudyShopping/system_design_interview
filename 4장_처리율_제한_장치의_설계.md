# 처리율 제한 장치의 설계

## 처리율 제한 장치 (Rate Limiter)
- 정의
	- 클라이언트 또는 서비스가 보내는 트래픽의 처리율(rate) 을 제어하기 위한 장치
	- ex. HTTP (제한 장치에 정의된 임계치(threshold) 를 넘어선 API 요청은 처리 중단 (Block))
- 장점
	- Dos(Denial of Service) 공격에 의한 자원 고갈(resource starvation) 방지
		- ex. [Twitter rate limit](https://developer.twitter.com/en/docs/basics/rate-limits) (300 tweets / 3h), [Google Docs API](https://developers.google.com/docs/api/limits) (300 read / 1m)
	- 비용 절감 : 서버 자원 혹은 써드파티 API 사용 횟수 절약
	- 서버 과부하 방지 : bot, 어뷰징 트래픽 필터링

### 1단계 - 문제 이해 및 설계 범위 확정

- 처리율 제한 장치 구현 방법
	- 각각의 장단점이 있는 여러가지 알고리즘 존재
	- 면접관과의 소통을 통해 어떤 장치를 구현해야하는지 구체화 (p.52-3)

> #### 시스템 요구사항 
> - threshold를 초과하는 요청에 대한 정확한 제한
> - Low Latency 
> - 적은 Memory Usage
> - 분산형 처리율 제한(distributed rate limiting)
> - 예외 처리 (=> 요청 제한 시 사용자에게 분명하게 알려야함)
> - 높은 Fault Tolerance

### 2단계 - 개략적 설계안 제시 및 동의 구하기

- 복잡하지 않은 기본적인 클라이언트-서버 통신 모델 사용
- **처리율 제한 장치는 어디에 둘 것인가?**
	- ~~client-side : 위변조가 쉽고 모든 클라이언트 구현 통제가 어려움~~ => 권장 X 
	- **server-side** : API 서버측에 직접 두거나 미들웨어로 통제
		- 처리율 제한 장치 미들웨어 구현 
			- API 서버로의 요청을 제어하는 미들웨어
				- HTTP Response `429 Too many requests` 응답
			- 클라우드 마이크로서비스 환경의 미들웨어 : **API Gateway 컴포넌트** 
				- API Gateway : 처리율 제한, SSL termination, Authentication, IP whitelist 관리 등을 지원하는 완전 위탁관리형 서비스 (fully managed)
	- 그래서 서버? 게이트웨이? 정답은 => **없다**
		- 회사의 현 기술 스택, 엔지니어링 인력, 우선순위, 목표에 따라 다름

> #### 판단 근거로 적용될 수 있는 지침
> - 현재 사용하고 있는 기술 스택 점검
> - 사업 요구사항에 맞는 처리율 제한 알고리즘 찾기
> - 설계 상 API 게이트웨이 사용 여부
> - 인력 여유에 따른 상용 API 게이트웨이 솔루션 사용


#### 처리율 제한 알고리즘
- 토큰 버킷 (token bucket)
	- API 요청 throttle 을 위한 보편적 솔루션
	- 동작 방식 : 분당 공급되는 토큰이 있는 경우에만 요청 처리
- 누출 버킷 (leaky bucket)
	- 요청 처리율이 고정되어있는 FIFO 큐 기반 솔루션
	- 동작 방식 : 큐에 요청을 추가하고 지정된 시간마다 처리. 큐가 가득차면 신규 요청 drop
- 고정 윈도 카운터 (fixed window counter)
	- 동작 방식 : 타임라인을 고정 간격의 윈도로 나눠 카운터 할당
- 이동 윈도 로깅 (sliding window log)
	- 고정 윈도의 트래픽 집중 시 문제점 해결
	- 동작 방식 : timestamp 기반으로 윈도 범위 내 로그의 크기를 허용치와 비교
- 이동 윈도 카운터 (sliding window counter)
	- 고정 윈도 카운터 + 이동 윈도 로깅
	- 동작 방식 : 현재 이동 윈도의 요청 수 = 현 1분 요청 수 + (직전 1분의 요청 수 * 겹치는 비율) 로 계산

| 알고리즘         | 장점                                                           | 단점                                                 | parameters                                    | 비고                                 |
|------------------|----------------------------------------------------------------|------------------------------------------------------|-----------------------------------------------|--------------------------------------|
| 토큰 버킷        | 구현 EASY, 메모리 효율, Burst of traffic 처리 가능             | params 튜닝의 어려움                                 | 버킷 크기 & 토큰 공급률(refill rate)          | 버킷의 개수는 공급 제한 규칙에 따라  |
| 누출 버킷        | 메모리 효율, 안정적 출력 (stable outflow rate)                 | params 튜닝의 어려움, 최신 요청의 버려짐             | 버킷 크기 (=큐 사이즈) & 처리율(outflow rate) |                                      |
| 고정 윈도 카운터 | 이해 EASY, 메모리 효율, 특정 트래픽 패턴 처리 적합             | 윈도 경계 부근에 트래픽이 몰리면 허용 한도 초과 처리 |                                               |                                      |
| 이동 윈도 로깅   | 정교하고 정확한 처리율 제한                                    | 다량의 메모리 사용 (전체 timestamp log 보관)         |                                               |                                      |
| 이동 윈도 카운터 | 메모리 효율, 트래픽 대응 원활 (이전 시간대의 평균 처리율 반영) | 추정치 계산이므로 다소 느슨한 처리                   |                                               | 두 가지 접근법 존재                  |

- 처리율 제한 알고리즘의 기본 아이디어 
	- *"얼마나 많은 요청이 접수되었는지 추적할 수 있는 카운터를 **대상별로** 두고, 이 **카운터의 값** 이 임계치를 넘어서면 한도를 넘어 도착한 요청은 거부한다"* 
	- 추적 대상 => 추적 대상은 사용자별로? IP주소별로? API endpoint나 서비스단위로?
	- 카운터의 값 저장 => 로컬에? DB에? 메모리 기반 저장장치(캐시)에?
		- Redis (인-메모리 데이터 스토어) : `INCR` `EXPIRE` 명령어 지원

<img src="https://user-images.githubusercontent.com/26691216/160273652-b725242b-54b1-4385-8a66-2aca1ea106aa.jpeg" width=400>

- 개략적인 아키텍처
	- 클라이언트가 처리율 제한 미들웨어에게 요청
	- 처리율 제한 미들웨어는 Redis의 지정 버킷에서 카운터를 가져옴
		- 한도에 도달했다면 요청은 거부
		- 한도에 도달하지 않았다면 요청은 API 서버로 전달
	- 미들웨어는 카운터 값을 증가시킨 후 다시 Redis 에 저장 (`INCR`)


### 3단계 - 상세 설계
- 개략적 아키텍쳐로 알 수 없는 것
	1. 처리율 제한 규칙은 어떻게 만들어지고 어디에 저장되는가?
	2. 처리가 제한된 요청들은 어떻게 처리되는가?
- 처리율 제한 규칙
	- 처리율 제한 오픈소스 사용 케이스 (ex. [Lyft - envoyproxy/ratelimit](https://github.com/lyft/ratelimit))
		- configuration file 형태로 디스크 저장
- 처리율 한도 초과 트래픽 처리
	- threshold에 걸린 API 요청은 `429 Too many requests` 응답
		- \+ HTTP Response Hader => 클라이언트가 본인의 요청이 처리율 제한에 걸린 것 (throttle) 을 감지하거나 요청량을 가늠
			- `X-Ratelimit-Remaining` (윈도 내 남은 처리 가능 요청 수)
			- `X-Ratelimit-Limit` (매 윈도마다 전송 가능한 요청 수)
			- `X-Ratelimit-Retry-After` (몇 초 뒤에 요청을 다시 보내야 유효 처리되는지)
	- 경우에 따라 나중에 다시 처리 하기위해 큐에 보관할 수도 있음 (=> Retry)

<img src="https://user-images.githubusercontent.com/26691216/160274137-38dc5dbd-fd1e-4773-a413-4ebaa5904d0d.jpeg" width=400>

- 상세한 설계 아키텍처
	- **처리율 제한 규칙** 은 디스크에 보관
		- 작업 프로세스(workers)는 수시로 규칙을 읽어 캐시에 저장
	- 클라이언트가 요청을 서버에 보내면 처리율 제한 미들웨어에 먼저 도달
	- 처리율 제한 미들웨어는 캐시에서 제한 규칙 & Redis 캐시에서 카운터와 마지막 요청의 timestamp 가져와서 판단
		- 요청이 처리율 제한에 걸린다면 클라이언트에게 `429 Too many requests` 응답 전송 (요청은 버리거나 메세지 큐로 보관)
		- 요청이 처리율 제한에 걸리지 않으면 API 서버로 전달

#### 분산 환경에서의 처리율 제한 기법
- 분산 환경에서 고려해야할 문제
	- 경쟁 조건 (race condition) 이슈 : 동시 요청 시 카운터 값 정합성 보장 필요
		- 락 (Lock) => 성능 저하 이슈 존재
		- 루아스크립트 (Luascript), Redis Sorted Set
		- ref. https://engineering.classdojo.com/blog/2015/02/06/rolling-rate-limiter/ https://stripe.com/blog/rate-limiters
	- 동기화 (synchronization) 이슈
		- 고정 세션 (sticky session) => 유연하지 못함
		- 중앙 집중형 데이터 저장소 사용
- 성능 최적화 방안
	- 여러 데이터센터 지원으로 트래픽을 가까운 에지 서버로 전달 (latency ↓)
	- 제한 장치간 데이터 동기화 시 최종 일관성 모델 (eventual consistency model) 사용 
- 모니터링
	- 채택된 처리율 제한 알고리즘이 효과적인가
	- 정의한 처리율 제한 규칙이 효과적인가

### 4단계 - 마무리
> 추가로 언급하면 좋을 부분들

- 경성(hard) or 연성(soft) 처리율 제한
	- 경성 처리율 제한 : 요청 개수는 임계치를 절대 넘을 수 없다
	- 연성 처리율 제한 : 요청 개수는 잠시 동안은 임계치를 넘어 설 수 있다
- 다양한 계층에서의 처리율 제한
	- 애플리케이션 계층 (HTTP - OSI 7)
	- 네트워크 계층 (Iptables 를 통한 IP 주소 기반 처리율 제한 - OSI 3)
- client-side 처리율 제한 회피
	- 클라이언트 캐시 사용을 통한 API 호출 횟수 감소
	- 처리율 제한 임계치 인지 및 메세지 전송 제한
	- 예외처리 코드를 통해 예외적 상황에 gracefully 한 복구
	- retry 로직 구현 시 충분한 back-off

---

### 참고용

> [Resilience4j](https://resilience4j.readme.io/docs) _ a lightweight Fault Tolerance Library

- TimeLimiter : 요청 응답시간 Timeout 시 Exception 발생
- CircuitBreaker : `일정 시간` or `일정 개수` 동안의 **실패율 (failure rate)** 계산 (threshold 초과 시 circuit open)
- RateLimiter : `일정 시간` 동안 **몇 개의 요청** 을 허용할지 (=SUM)
- BulkHead : 몇개의 동시 호풀을 허용할지 (=MAX)
- Retry : Exception 발생 시 재 시도 or 무시

